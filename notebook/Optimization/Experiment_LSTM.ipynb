{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from small_script.myFunctions import *\n",
    "import feather\n",
    "import Bio.PDB as bio\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "d3_to_index = bio.Polypeptide.d3_to_index  # we may want to adjust this in the future.\n",
    "three_to_one = bio.Polypeptide.three_to_one\n",
    "one_to_index = bio.Polypeptide.one_to_index\n",
    "plt.rcParams['figure.figsize'] = [16.18033, 10]\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFragPdb(pdbId, i, outFile=None):\n",
    "    pdb = pdbId + \".pdb\"\n",
    "    if outFile is None:\n",
    "        outFile = f\"{i}_{pdb}\"\n",
    "#     pdb = \"1igqB00.pdb\"\n",
    "#     pdbId = pdb.split('.')[0]\n",
    "    pre = \"/Users/weilu/Research/optimization/fragment/\"\n",
    "    database = \"/Users/weilu/Research/optimization/fragment/database/dompdb/\"\n",
    "    parser = bio.PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"x\", os.path.join(database, pdb))\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            all_residues = list(chain)\n",
    "            io = bio.PDBIO()\n",
    "            c = bio.Chain.Chain(\"A\")\n",
    "            c.child_list = all_residues[i:i+9]\n",
    "#             for ii, res in enumerate(c):\n",
    "#                 res.id = (' ', ii+1, ' ')\n",
    "            io.set_structure(c)\n",
    "            io.save(f'{pre}{outFile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = feather.read_dataframe(\"/Users/weilu/Research/optimization/fragment/cluster100.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random structure from 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data_original.query(\"cluster < 5\").groupby(\"cluster\").apply(pd.DataFrame.sample, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3un9A01 55 0\n",
      "1 2vovA00 163 0\n",
      "2 3psfA03 228 0\n",
      "3 4nn5B01 20 0\n",
      "4 1zu0A03 84 1\n",
      "5 1jplA00 86 1\n",
      "6 4ovjA02 77 1\n",
      "7 5lozA00 112 1\n",
      "8 4g0aA01 3 2\n",
      "9 3lppA02 115 2\n",
      "10 1umhA00 32 2\n",
      "11 2jgvB00 157 2\n",
      "12 2c43A01 17 3\n",
      "13 2c9eA00 13 3\n",
      "14 4lr2A01 86 3\n",
      "15 3zheB02 116 3\n",
      "16 2taaA02 55 4\n",
      "17 3doaA01 118 4\n",
      "18 1ywkC00 217 4\n",
      "19 3ty1A00 204 4\n"
     ]
    }
   ],
   "source": [
    "for i, row in t.reset_index(drop=True).iterrows():\n",
    "    print(i, row[\"pdb\"], row[\"i\"], row[\"cluster\"])\n",
    "    getFragPdb(row[\"pdb\"], int(row[\"i\"]), f\"cluster0to4/{i}_cluster_{row['cluster']}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weilu/Research/optimization/fragment/cluster0to4/5_cluster_1.pdb\n",
      "5_cluster_1\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/1_cluster_0.pdb\n",
      "1_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/13_cluster_3.pdb\n",
      "13_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/17_cluster_4.pdb\n",
      "17_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/10_cluster_2.pdb\n",
      "10_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/6_cluster_1.pdb\n",
      "6_cluster_1\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/14_cluster_3.pdb\n",
      "14_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/2_cluster_0.pdb\n",
      "2_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/8_cluster_2.pdb\n",
      "8_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/19_cluster_4.pdb\n",
      "19_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/18_cluster_4.pdb\n",
      "18_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/9_cluster_2.pdb\n",
      "9_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/16_cluster_4.pdb\n",
      "16_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/15_cluster_3.pdb\n",
      "15_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/3_cluster_0.pdb\n",
      "3_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/11_cluster_2.pdb\n",
      "11_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/7_cluster_1.pdb\n",
      "7_cluster_1\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/12_cluster_3.pdb\n",
      "12_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/0_cluster_0.pdb\n",
      "0_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4/4_cluster_1.pdb\n",
      "4_cluster_1\n"
     ]
    }
   ],
   "source": [
    "# compute the rmsd with respect to the pdb that closest to the cluster center\n",
    "pre = \"/Users/weilu/Research/optimization/fragment/\"\n",
    "pdbList = glob.glob(f\"{pre}cluster0to4/[0-9]*.pdb\")\n",
    "with open(pre+\"cluster0to4_rmsd.csv\", \"w\") as out:\n",
    "    out.write(\"i,j,rmsd\\n\")\n",
    "    for p1 in pdbList:\n",
    "        print(p1)\n",
    "        i1 = p1.split(\"/\")[-1].split(\".\")[0]\n",
    "#         if i1 != 0:\n",
    "#             continue\n",
    "        print(i1)\n",
    "        for p2 in pdbList:\n",
    "            i2 = p2.split(\"/\")[-1].split(\".\")[0]\n",
    "            rmsd = float(getFromTerminal(f\"calculate_rmsd.py {p1} {p2}\"))\n",
    "            out.write(f\"{i1},{i2},{rmsd}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_rmsd = pd.read_csv(pre+\"cluster0to4_rmsd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_rmsd[\"rmsd\"] = cluster_rmsd[\"rmsd\"].round(3)\n",
    "cluster_rmsd[\"ii\"] = cluster_rmsd[\"i\"].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "cluster_rmsd[\"jj\"] = cluster_rmsd[\"j\"].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "cluster_rmsd = cluster_rmsd.sort_values([\"ii\", \"jj\"])\n",
    "t = cluster_rmsd.pivot(index=\"ii\", columns=\"jj\", values=\"rmsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1ad7417f0>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1164.98x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [16.18033, 10]\n",
    "plt.imshow(t, cmap=\"Greys\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data_original.query(\"cluster < 5\").groupby(\"cluster\").head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1g9mG00 206 0\n",
      "1 1wyuB03 158 0\n",
      "2 1gqiA02 246 0\n",
      "3 4c8pA00 89 0\n",
      "4 5cr9A02 26 1\n",
      "5 1ic2A00 11 1\n",
      "6 4r33A00 51 1\n",
      "7 1oaoC03 163 1\n",
      "8 2h7fX02 93 2\n",
      "9 2w2iA00 179 2\n",
      "10 1d7pM00 117 2\n",
      "11 2q83A02 121 2\n",
      "12 2q9oA03 200 3\n",
      "13 1vchD00 41 3\n",
      "14 1uqtA01 108 3\n",
      "15 1ej6B00 574 3\n",
      "16 4yokA01 40 4\n",
      "17 2e8yA01 70 4\n",
      "18 3pjyA00 7 4\n",
      "19 3sluB01 51 4\n"
     ]
    }
   ],
   "source": [
    "folder = \"cluster0to4_center\"\n",
    "for i, row in t.reset_index(drop=True).iterrows():\n",
    "#     print(i, row[\"pdb\"], row[\"i\"], row[\"cluster\"])\n",
    "    getFragPdb(row[\"pdb\"], int(row[\"i\"]), f\"{folder}/{i}_cluster_{row['cluster']}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/5_cluster_1.pdb\n",
      "5_cluster_1\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/1_cluster_0.pdb\n",
      "1_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/13_cluster_3.pdb\n",
      "13_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/17_cluster_4.pdb\n",
      "17_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/10_cluster_2.pdb\n",
      "10_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/6_cluster_1.pdb\n",
      "6_cluster_1\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/14_cluster_3.pdb\n",
      "14_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/2_cluster_0.pdb\n",
      "2_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/8_cluster_2.pdb\n",
      "8_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/19_cluster_4.pdb\n",
      "19_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/18_cluster_4.pdb\n",
      "18_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/9_cluster_2.pdb\n",
      "9_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/16_cluster_4.pdb\n",
      "16_cluster_4\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/15_cluster_3.pdb\n",
      "15_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/3_cluster_0.pdb\n",
      "3_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/11_cluster_2.pdb\n",
      "11_cluster_2\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/7_cluster_1.pdb\n",
      "7_cluster_1\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/12_cluster_3.pdb\n",
      "12_cluster_3\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/0_cluster_0.pdb\n",
      "0_cluster_0\n",
      "/Users/weilu/Research/optimization/fragment/cluster0to4_center/4_cluster_1.pdb\n",
      "4_cluster_1\n"
     ]
    }
   ],
   "source": [
    "# compute the rmsd with respect to the pdb that closest to the cluster center\n",
    "\n",
    "pre = \"/Users/weilu/Research/optimization/fragment/\"\n",
    "pdbList = glob.glob(f\"{pre}{folder}/[0-9]*.pdb\")\n",
    "with open(pre+f\"{folder}_rmsd.csv\", \"w\") as out:\n",
    "    out.write(\"i,j,rmsd\\n\")\n",
    "    for p1 in pdbList:\n",
    "        print(p1)\n",
    "        i1 = p1.split(\"/\")[-1].split(\".\")[0]\n",
    "#         if i1 != 0:\n",
    "#             continue\n",
    "        print(i1)\n",
    "        for p2 in pdbList:\n",
    "            i2 = p2.split(\"/\")[-1].split(\".\")[0]\n",
    "            rmsd = float(getFromTerminal(f\"calculate_rmsd.py {p1} {p2}\"))\n",
    "            out.write(f\"{i1},{i2},{rmsd}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_rmsd = pd.read_csv(pre+f\"{folder}_rmsd.csv\")\n",
    "cluster_rmsd[\"rmsd\"] = cluster_rmsd[\"rmsd\"].round(3)\n",
    "cluster_rmsd[\"ii\"] = cluster_rmsd[\"i\"].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "cluster_rmsd[\"jj\"] = cluster_rmsd[\"j\"].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "cluster_rmsd = cluster_rmsd.sort_values([\"ii\", \"jj\"])\n",
    "t = cluster_rmsd.pivot(index=\"ii\", columns=\"jj\", values=\"rmsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1c6f450b8>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1164.98x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [16.18033, 10]\n",
    "plt.imshow(t, cmap=\"Greys\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1901430, 89)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>caca_1</th>\n",
       "      <th>caca_2</th>\n",
       "      <th>caca_3</th>\n",
       "      <th>caca_4</th>\n",
       "      <th>caca_5</th>\n",
       "      <th>caca_6</th>\n",
       "      <th>caca_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cbcb_14</th>\n",
       "      <th>cbcb_15</th>\n",
       "      <th>cbcb_16</th>\n",
       "      <th>cbcb_17</th>\n",
       "      <th>cbcb_18</th>\n",
       "      <th>cbcb_19</th>\n",
       "      <th>cbcb_20</th>\n",
       "      <th>cbcb_21</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1g9mG00</td>\n",
       "      <td>206</td>\n",
       "      <td>FFYCNSTQL</td>\n",
       "      <td>9.879721</td>\n",
       "      <td>13.365485</td>\n",
       "      <td>15.387287</td>\n",
       "      <td>18.605337</td>\n",
       "      <td>20.240051</td>\n",
       "      <td>19.853123</td>\n",
       "      <td>9.830854</td>\n",
       "      <td>...</td>\n",
       "      <td>14.465818</td>\n",
       "      <td>14.041501</td>\n",
       "      <td>9.975571</td>\n",
       "      <td>9.917680</td>\n",
       "      <td>9.397504</td>\n",
       "      <td>7.394856</td>\n",
       "      <td>9.067275</td>\n",
       "      <td>4.491067</td>\n",
       "      <td>4.966916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1wyuB03</td>\n",
       "      <td>158</td>\n",
       "      <td>QLYYDGANL</td>\n",
       "      <td>9.870072</td>\n",
       "      <td>12.872975</td>\n",
       "      <td>15.433169</td>\n",
       "      <td>18.492691</td>\n",
       "      <td>19.469760</td>\n",
       "      <td>19.349613</td>\n",
       "      <td>9.869476</td>\n",
       "      <td>...</td>\n",
       "      <td>13.653317</td>\n",
       "      <td>13.835575</td>\n",
       "      <td>9.690599</td>\n",
       "      <td>9.644212</td>\n",
       "      <td>8.670468</td>\n",
       "      <td>7.562226</td>\n",
       "      <td>9.338580</td>\n",
       "      <td>4.768490</td>\n",
       "      <td>5.051766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1gqiA02</td>\n",
       "      <td>246</td>\n",
       "      <td>THLAYQGPL</td>\n",
       "      <td>9.443632</td>\n",
       "      <td>12.430652</td>\n",
       "      <td>14.523600</td>\n",
       "      <td>17.825624</td>\n",
       "      <td>19.053972</td>\n",
       "      <td>18.688576</td>\n",
       "      <td>9.596665</td>\n",
       "      <td>...</td>\n",
       "      <td>12.804110</td>\n",
       "      <td>13.845181</td>\n",
       "      <td>10.013397</td>\n",
       "      <td>9.532242</td>\n",
       "      <td>8.748777</td>\n",
       "      <td>6.784276</td>\n",
       "      <td>8.743169</td>\n",
       "      <td>4.850136</td>\n",
       "      <td>5.151431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4c8pA00</td>\n",
       "      <td>89</td>\n",
       "      <td>AVIFDVSEN</td>\n",
       "      <td>9.920808</td>\n",
       "      <td>13.207690</td>\n",
       "      <td>15.512877</td>\n",
       "      <td>18.683271</td>\n",
       "      <td>20.596830</td>\n",
       "      <td>19.606644</td>\n",
       "      <td>9.877905</td>\n",
       "      <td>...</td>\n",
       "      <td>14.648695</td>\n",
       "      <td>13.808992</td>\n",
       "      <td>9.533399</td>\n",
       "      <td>10.704074</td>\n",
       "      <td>8.485997</td>\n",
       "      <td>8.005937</td>\n",
       "      <td>8.796261</td>\n",
       "      <td>5.409743</td>\n",
       "      <td>5.206578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3stoA01</td>\n",
       "      <td>171</td>\n",
       "      <td>KNTLDLVPT</td>\n",
       "      <td>10.185408</td>\n",
       "      <td>13.765726</td>\n",
       "      <td>15.791227</td>\n",
       "      <td>19.181437</td>\n",
       "      <td>20.328955</td>\n",
       "      <td>19.526373</td>\n",
       "      <td>10.073597</td>\n",
       "      <td>...</td>\n",
       "      <td>13.647936</td>\n",
       "      <td>13.585122</td>\n",
       "      <td>9.760163</td>\n",
       "      <td>9.854342</td>\n",
       "      <td>8.159576</td>\n",
       "      <td>6.618244</td>\n",
       "      <td>8.337652</td>\n",
       "      <td>5.255162</td>\n",
       "      <td>5.255510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pdb    i        seq     caca_1     caca_2     caca_3     caca_4  \\\n",
       "0  1g9mG00  206  FFYCNSTQL   9.879721  13.365485  15.387287  18.605337   \n",
       "1  1wyuB03  158  QLYYDGANL   9.870072  12.872975  15.433169  18.492691   \n",
       "2  1gqiA02  246  THLAYQGPL   9.443632  12.430652  14.523600  17.825624   \n",
       "3  4c8pA00   89  AVIFDVSEN   9.920808  13.207690  15.512877  18.683271   \n",
       "4  3stoA01  171  KNTLDLVPT  10.185408  13.765726  15.791227  19.181437   \n",
       "\n",
       "      caca_5     caca_6     caca_7   ...       cbcb_14    cbcb_15    cbcb_16  \\\n",
       "0  20.240051  19.853123   9.830854   ...     14.465818  14.041501   9.975571   \n",
       "1  19.469760  19.349613   9.869476   ...     13.653317  13.835575   9.690599   \n",
       "2  19.053972  18.688576   9.596665   ...     12.804110  13.845181  10.013397   \n",
       "3  20.596830  19.606644   9.877905   ...     14.648695  13.808992   9.533399   \n",
       "4  20.328955  19.526373  10.073597   ...     13.647936  13.585122   9.760163   \n",
       "\n",
       "     cbcb_17   cbcb_18   cbcb_19   cbcb_20   cbcb_21      rmsd  cluster  \n",
       "0   9.917680  9.397504  7.394856  9.067275  4.491067  4.966916        0  \n",
       "1   9.644212  8.670468  7.562226  9.338580  4.768490  5.051766        0  \n",
       "2   9.532242  8.748777  6.784276  8.743169  4.850136  5.151431        0  \n",
       "3  10.704074  8.485997  8.005937  8.796261  5.409743  5.206578        0  \n",
       "4   9.854342  8.159576  6.618244  8.337652  5.255162  5.255510        0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    382971\n",
       "2     28523\n",
       "4     22208\n",
       "3     21066\n",
       "0     10646\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.query(\"cluster < 5\")[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>caca_1</th>\n",
       "      <th>caca_2</th>\n",
       "      <th>caca_3</th>\n",
       "      <th>caca_4</th>\n",
       "      <th>caca_5</th>\n",
       "      <th>caca_6</th>\n",
       "      <th>caca_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cbcb_14</th>\n",
       "      <th>cbcb_15</th>\n",
       "      <th>cbcb_16</th>\n",
       "      <th>cbcb_17</th>\n",
       "      <th>cbcb_18</th>\n",
       "      <th>cbcb_19</th>\n",
       "      <th>cbcb_20</th>\n",
       "      <th>cbcb_21</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1g9mG00</td>\n",
       "      <td>206</td>\n",
       "      <td>FFYCNSTQL</td>\n",
       "      <td>9.879721</td>\n",
       "      <td>13.365485</td>\n",
       "      <td>15.387287</td>\n",
       "      <td>18.605337</td>\n",
       "      <td>20.240051</td>\n",
       "      <td>19.853123</td>\n",
       "      <td>9.830854</td>\n",
       "      <td>...</td>\n",
       "      <td>14.465818</td>\n",
       "      <td>14.041501</td>\n",
       "      <td>9.975571</td>\n",
       "      <td>9.917680</td>\n",
       "      <td>9.397504</td>\n",
       "      <td>7.394856</td>\n",
       "      <td>9.067275</td>\n",
       "      <td>4.491067</td>\n",
       "      <td>4.966916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1wyuB03</td>\n",
       "      <td>158</td>\n",
       "      <td>QLYYDGANL</td>\n",
       "      <td>9.870072</td>\n",
       "      <td>12.872975</td>\n",
       "      <td>15.433169</td>\n",
       "      <td>18.492691</td>\n",
       "      <td>19.469760</td>\n",
       "      <td>19.349613</td>\n",
       "      <td>9.869476</td>\n",
       "      <td>...</td>\n",
       "      <td>13.653317</td>\n",
       "      <td>13.835575</td>\n",
       "      <td>9.690599</td>\n",
       "      <td>9.644212</td>\n",
       "      <td>8.670468</td>\n",
       "      <td>7.562226</td>\n",
       "      <td>9.338580</td>\n",
       "      <td>4.768490</td>\n",
       "      <td>5.051766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1gqiA02</td>\n",
       "      <td>246</td>\n",
       "      <td>THLAYQGPL</td>\n",
       "      <td>9.443632</td>\n",
       "      <td>12.430652</td>\n",
       "      <td>14.523600</td>\n",
       "      <td>17.825624</td>\n",
       "      <td>19.053972</td>\n",
       "      <td>18.688576</td>\n",
       "      <td>9.596665</td>\n",
       "      <td>...</td>\n",
       "      <td>12.804110</td>\n",
       "      <td>13.845181</td>\n",
       "      <td>10.013397</td>\n",
       "      <td>9.532242</td>\n",
       "      <td>8.748777</td>\n",
       "      <td>6.784276</td>\n",
       "      <td>8.743169</td>\n",
       "      <td>4.850136</td>\n",
       "      <td>5.151431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4c8pA00</td>\n",
       "      <td>89</td>\n",
       "      <td>AVIFDVSEN</td>\n",
       "      <td>9.920808</td>\n",
       "      <td>13.207690</td>\n",
       "      <td>15.512877</td>\n",
       "      <td>18.683271</td>\n",
       "      <td>20.596830</td>\n",
       "      <td>19.606644</td>\n",
       "      <td>9.877905</td>\n",
       "      <td>...</td>\n",
       "      <td>14.648695</td>\n",
       "      <td>13.808992</td>\n",
       "      <td>9.533399</td>\n",
       "      <td>10.704074</td>\n",
       "      <td>8.485997</td>\n",
       "      <td>8.005937</td>\n",
       "      <td>8.796261</td>\n",
       "      <td>5.409743</td>\n",
       "      <td>5.206578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3stoA01</td>\n",
       "      <td>171</td>\n",
       "      <td>KNTLDLVPT</td>\n",
       "      <td>10.185408</td>\n",
       "      <td>13.765726</td>\n",
       "      <td>15.791227</td>\n",
       "      <td>19.181437</td>\n",
       "      <td>20.328955</td>\n",
       "      <td>19.526373</td>\n",
       "      <td>10.073597</td>\n",
       "      <td>...</td>\n",
       "      <td>13.647936</td>\n",
       "      <td>13.585122</td>\n",
       "      <td>9.760163</td>\n",
       "      <td>9.854342</td>\n",
       "      <td>8.159576</td>\n",
       "      <td>6.618244</td>\n",
       "      <td>8.337652</td>\n",
       "      <td>5.255162</td>\n",
       "      <td>5.255510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pdb    i        seq     caca_1     caca_2     caca_3     caca_4  \\\n",
       "0  1g9mG00  206  FFYCNSTQL   9.879721  13.365485  15.387287  18.605337   \n",
       "1  1wyuB03  158  QLYYDGANL   9.870072  12.872975  15.433169  18.492691   \n",
       "2  1gqiA02  246  THLAYQGPL   9.443632  12.430652  14.523600  17.825624   \n",
       "3  4c8pA00   89  AVIFDVSEN   9.920808  13.207690  15.512877  18.683271   \n",
       "4  3stoA01  171  KNTLDLVPT  10.185408  13.765726  15.791227  19.181437   \n",
       "\n",
       "      caca_5     caca_6     caca_7   ...       cbcb_14    cbcb_15    cbcb_16  \\\n",
       "0  20.240051  19.853123   9.830854   ...     14.465818  14.041501   9.975571   \n",
       "1  19.469760  19.349613   9.869476   ...     13.653317  13.835575   9.690599   \n",
       "2  19.053972  18.688576   9.596665   ...     12.804110  13.845181  10.013397   \n",
       "3  20.596830  19.606644   9.877905   ...     14.648695  13.808992   9.533399   \n",
       "4  20.328955  19.526373  10.073597   ...     13.647936  13.585122   9.760163   \n",
       "\n",
       "     cbcb_17   cbcb_18   cbcb_19   cbcb_20   cbcb_21      rmsd  cluster  \n",
       "0   9.917680  9.397504  7.394856  9.067275  4.491067  4.966916        0  \n",
       "1   9.644212  8.670468  7.562226  9.338580  4.768490  5.051766        0  \n",
       "2   9.532242  8.748777  6.784276  8.743169  4.850136  5.151431        0  \n",
       "3  10.704074  8.485997  8.005937  8.796261  5.409743  5.206578        0  \n",
       "4   9.854342  8.159576  6.618244  8.337652  5.255162  5.255510        0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = feather.read_dataframe(\"/Users/weilu/Research/optimization/fragment/cluster100_v2.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_original[[\"pdb\", \"i\", \"seq\",\"cluster\", \"rmsd\"]].reset_index(drop=True)\n",
    "data[\"cluster\"] = data[\"cluster\"].astype(int)\n",
    "for i in range(1,10):\n",
    "    data[f\"s{i}\"] = data[\"seq\"].apply(lambda x: one_to_index(x[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_feather(\"/Users/weilu/Research/optimization/fragment/cluster100_v2_processed.feather\")\n",
    "# data.to_feather(\"/Users/weilu/Research/optimization/fragment/cluster100_processed.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(\"/Users/weilu/Research/optimization/fragment/cluster100_processed.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(\"/Users/weilu/Research/optimization/fragment/cluster100_v2_processed.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>cluster</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1bg6A02</td>\n",
       "      <td>107</td>\n",
       "      <td>RAVNVPTPL</td>\n",
       "      <td>0</td>\n",
       "      <td>5.756177</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3g85A02</td>\n",
       "      <td>38</td>\n",
       "      <td>HKNGIKISE</td>\n",
       "      <td>0</td>\n",
       "      <td>6.329374</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4je5C00</td>\n",
       "      <td>166</td>\n",
       "      <td>EAQGVITFP</td>\n",
       "      <td>0</td>\n",
       "      <td>6.365145</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3q41A01</td>\n",
       "      <td>88</td>\n",
       "      <td>GFYRIPVLG</td>\n",
       "      <td>0</td>\n",
       "      <td>6.389094</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1auqA00</td>\n",
       "      <td>144</td>\n",
       "      <td>KKKKVIVIP</td>\n",
       "      <td>0</td>\n",
       "      <td>6.450880</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pdb    i        seq  cluster      rmsd  s1  s2  s3  s4  s5  s6  s7  s8  \\\n",
       "0  1bg6A02  107  RAVNVPTPL        0  5.756177  14   0  17  11  17  12  16  12   \n",
       "1  3g85A02   38  HKNGIKISE        0  6.329374   6   8  11   5   7   8   7  15   \n",
       "2  4je5C00  166  EAQGVITFP        0  6.365145   3   0  13   5  17   7  16   4   \n",
       "3  3q41A01   88  GFYRIPVLG        0  6.389094   5   4  19  14   7  12  17   9   \n",
       "4  1auqA00  144  KKKKVIVIP        0  6.450880   8   8   8   8  17   7  17   7   \n",
       "\n",
       "   s9  \n",
       "0   9  \n",
       "1   3  \n",
       "2  12  \n",
       "3   5  \n",
       "4  12  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query(\"cluster < 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    382971\n",
       "0     10646\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 9\n",
    "test = data.groupby(\"cluster\").apply(pd.DataFrame.sample, 10000, replace=True)\n",
    "# test = data.query(\"category > -1 and category < 10\").sample(10000)\n",
    "x_train = test.iloc[:, 5:14].values\n",
    "y_train_value = test[\"cluster\"].values\n",
    "test = data.groupby(\"cluster\").apply(pd.DataFrame.sample, 10000, replace=True)\n",
    "# test = data.query(\"category > -1 and category < 10\").sample(10000)\n",
    "x_test = test.iloc[:, 5:14].values\n",
    "y_test_value = test[\"cluster\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (20000, 9)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 9\n",
    "test = data.groupby(\"cluster\").apply(pd.DataFrame.sample, 10000, replace=True)\n",
    "# test = data.query(\"category > -1 and category < 10\").sample(10000)\n",
    "x_train = test.iloc[:, 5:14].values\n",
    "y_train_value = test[\"cluster\"].values\n",
    "test = data.groupby(\"cluster\").apply(pd.DataFrame.sample, 10000, replace=True)\n",
    "# test = data.query(\"category > -1 and category < 10\").sample(10000)\n",
    "x_test = test.iloc[:, 5:14].values\n",
    "y_test_value = test[\"cluster\"].values\n",
    "\n",
    "# print('Pad sequences (samples x time)')\n",
    "# x_train1 = sequence.pad_sequences(x_train, maxlen=10)\n",
    "# x_test1 = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "y_train = to_categorical(np.array(y_train_value))\n",
    "y_test = to_categorical(np.array(y_test_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weilu/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(x_train1 == x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 train sequences\n",
      "Train...\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/40\n",
      "20000/20000 [==============================] - 9s 456us/step - loss: 0.6777 - acc: 0.6865 - val_loss: 0.6499 - val_acc: 0.7552\n",
      "Epoch 2/40\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.6063 - acc: 0.7463 - val_loss: 0.5310 - val_acc: 0.7519\n",
      "Epoch 3/40\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.5059 - acc: 0.7521 - val_loss: 0.4727 - val_acc: 0.7712\n",
      "Epoch 4/40\n",
      "20000/20000 [==============================] - 3s 173us/step - loss: 0.4595 - acc: 0.7837 - val_loss: 0.4319 - val_acc: 0.8012\n",
      "Epoch 5/40\n",
      "20000/20000 [==============================] - 3s 170us/step - loss: 0.4318 - acc: 0.8013 - val_loss: 0.4096 - val_acc: 0.8093\n",
      "Epoch 6/40\n",
      "20000/20000 [==============================] - 3s 169us/step - loss: 0.4102 - acc: 0.8122 - val_loss: 0.3900 - val_acc: 0.8214\n",
      "Epoch 7/40\n",
      "20000/20000 [==============================] - 4s 186us/step - loss: 0.3999 - acc: 0.8195 - val_loss: 0.3890 - val_acc: 0.8235\n",
      "Epoch 8/40\n",
      "20000/20000 [==============================] - 4s 177us/step - loss: 0.3970 - acc: 0.8205 - val_loss: 0.3868 - val_acc: 0.8243\n",
      "Epoch 9/40\n",
      "20000/20000 [==============================] - 4s 184us/step - loss: 0.3963 - acc: 0.8219 - val_loss: 0.3861 - val_acc: 0.8252\n",
      "Epoch 10/40\n",
      "20000/20000 [==============================] - 4s 177us/step - loss: 0.3940 - acc: 0.8230 - val_loss: 0.3841 - val_acc: 0.8250\n",
      "Epoch 11/40\n",
      "20000/20000 [==============================] - 4s 186us/step - loss: 0.3929 - acc: 0.8228 - val_loss: 0.3828 - val_acc: 0.8247\n",
      "Epoch 12/40\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.3901 - acc: 0.8237 - val_loss: 0.3804 - val_acc: 0.8262\n",
      "Epoch 13/40\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.3886 - acc: 0.8258 - val_loss: 0.3783 - val_acc: 0.8274\n",
      "Epoch 14/40\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.3845 - acc: 0.8261 - val_loss: 0.3748 - val_acc: 0.8300\n",
      "Epoch 15/40\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.3808 - acc: 0.8301 - val_loss: 0.3716 - val_acc: 0.8323\n",
      "Epoch 16/40\n",
      "20000/20000 [==============================] - 3s 175us/step - loss: 0.3779 - acc: 0.8298 - val_loss: 0.3693 - val_acc: 0.8326\n",
      "Epoch 17/40\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.3754 - acc: 0.8313 - val_loss: 0.3675 - val_acc: 0.8358\n",
      "Epoch 18/40\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.3738 - acc: 0.8320 - val_loss: 0.3680 - val_acc: 0.8335\n",
      "Epoch 19/40\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.3717 - acc: 0.8334 - val_loss: 0.3648 - val_acc: 0.8352\n",
      "Epoch 20/40\n",
      "20000/20000 [==============================] - 3s 166us/step - loss: 0.3705 - acc: 0.8349 - val_loss: 0.3635 - val_acc: 0.8369\n",
      "Epoch 21/40\n",
      "20000/20000 [==============================] - 4s 184us/step - loss: 0.3701 - acc: 0.8358 - val_loss: 0.3626 - val_acc: 0.8370\n",
      "Epoch 22/40\n",
      "20000/20000 [==============================] - 3s 175us/step - loss: 0.3695 - acc: 0.8352 - val_loss: 0.3622 - val_acc: 0.8371\n",
      "Epoch 23/40\n",
      "20000/20000 [==============================] - 4s 184us/step - loss: 0.3692 - acc: 0.8341 - val_loss: 0.3615 - val_acc: 0.8370\n",
      "Epoch 24/40\n",
      "20000/20000 [==============================] - 3s 170us/step - loss: 0.3675 - acc: 0.8350 - val_loss: 0.3611 - val_acc: 0.8396\n",
      "Epoch 25/40\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.3669 - acc: 0.8355 - val_loss: 0.3598 - val_acc: 0.8388\n",
      "Epoch 26/40\n",
      "20000/20000 [==============================] - 3s 173us/step - loss: 0.3667 - acc: 0.8361 - val_loss: 0.3597 - val_acc: 0.8389\n",
      "Epoch 27/40\n",
      "20000/20000 [==============================] - 3s 171us/step - loss: 0.3657 - acc: 0.8364 - val_loss: 0.3590 - val_acc: 0.8392\n",
      "Epoch 28/40\n",
      "20000/20000 [==============================] - 3s 165us/step - loss: 0.3641 - acc: 0.8366 - val_loss: 0.3587 - val_acc: 0.8397\n",
      "Epoch 29/40\n",
      "20000/20000 [==============================] - 3s 170us/step - loss: 0.3642 - acc: 0.8366 - val_loss: 0.3595 - val_acc: 0.8398\n",
      "Epoch 30/40\n",
      "20000/20000 [==============================] - 3s 166us/step - loss: 0.3653 - acc: 0.8361 - val_loss: 0.3598 - val_acc: 0.8392\n",
      "Epoch 31/40\n",
      "20000/20000 [==============================] - 3s 167us/step - loss: 0.3637 - acc: 0.8393 - val_loss: 0.3585 - val_acc: 0.8400\n",
      "Epoch 32/40\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.3633 - acc: 0.8380 - val_loss: 0.3571 - val_acc: 0.8400\n",
      "Epoch 33/40\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.3630 - acc: 0.8376 - val_loss: 0.3565 - val_acc: 0.8407\n",
      "Epoch 34/40\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.3626 - acc: 0.8380 - val_loss: 0.3564 - val_acc: 0.8414\n",
      "Epoch 35/40\n",
      "20000/20000 [==============================] - 3s 165us/step - loss: 0.3630 - acc: 0.8387 - val_loss: 0.3565 - val_acc: 0.8399\n",
      "Epoch 36/40\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.3605 - acc: 0.8390 - val_loss: 0.3555 - val_acc: 0.8418\n",
      "Epoch 37/40\n",
      "20000/20000 [==============================] - 3s 161us/step - loss: 0.3603 - acc: 0.8401 - val_loss: 0.3551 - val_acc: 0.8418\n",
      "Epoch 38/40\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.3587 - acc: 0.8401 - val_loss: 0.3549 - val_acc: 0.8416\n",
      "Epoch 39/40\n",
      "20000/20000 [==============================] - 4s 189us/step - loss: 0.3587 - acc: 0.8402 - val_loss: 0.3547 - val_acc: 0.8425\n",
      "Epoch 40/40\n",
      "20000/20000 [==============================] - 4s 185us/step - loss: 0.3575 - acc: 0.8399 - val_loss: 0.3537 - val_acc: 0.8430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2239de438>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "max_features = 100\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "\n",
    "batch_size = 1024*2\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "# model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=40,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 9, 128)            12800     \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 111,874\n",
      "Trainable params: 111,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 9, 128)            2560      \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 101,634\n",
      "Trainable params: 101,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 train sequences\n",
      "Train...\n",
      "Train on 1000000 samples, validate on 1000000 samples\n",
      "Epoch 1/40\n",
      "1000000/1000000 [==============================] - 203s 203us/step - loss: 4.3113 - acc: 0.0507 - val_loss: 4.1467 - val_acc: 0.0794\n",
      "Epoch 2/40\n",
      "1000000/1000000 [==============================] - 194s 194us/step - loss: 4.1239 - acc: 0.0827 - val_loss: 4.0079 - val_acc: 0.1031\n",
      "Epoch 3/40\n",
      "1000000/1000000 [==============================] - 196s 196us/step - loss: 4.0236 - acc: 0.1016 - val_loss: 3.9225 - val_acc: 0.1182\n",
      "Epoch 4/40\n",
      "1000000/1000000 [==============================] - 192s 192us/step - loss: 3.9654 - acc: 0.1115 - val_loss: 3.8749 - val_acc: 0.1254\n",
      "Epoch 5/40\n",
      "1000000/1000000 [==============================] - 184s 184us/step - loss: 3.9337 - acc: 0.1167 - val_loss: 3.8524 - val_acc: 0.1293\n",
      "Epoch 6/40\n",
      "1000000/1000000 [==============================] - 198s 198us/step - loss: 3.9151 - acc: 0.1201 - val_loss: 3.8367 - val_acc: 0.1316\n",
      "Epoch 7/40\n",
      "1000000/1000000 [==============================] - 189s 189us/step - loss: 3.9025 - acc: 0.1219 - val_loss: 3.8208 - val_acc: 0.1340\n",
      "Epoch 8/40\n",
      "1000000/1000000 [==============================] - 183s 183us/step - loss: 3.8927 - acc: 0.1234 - val_loss: 3.8179 - val_acc: 0.1354\n",
      "Epoch 9/40\n",
      "1000000/1000000 [==============================] - 190s 190us/step - loss: 3.8843 - acc: 0.1252 - val_loss: 3.8079 - val_acc: 0.1365\n",
      "Epoch 10/40\n",
      "1000000/1000000 [==============================] - 187s 187us/step - loss: 3.8768 - acc: 0.1265 - val_loss: 3.7970 - val_acc: 0.1379\n",
      "Epoch 11/40\n",
      "1000000/1000000 [==============================] - 180s 180us/step - loss: 3.8713 - acc: 0.1280 - val_loss: 3.7946 - val_acc: 0.1388\n",
      "Epoch 12/40\n",
      "1000000/1000000 [==============================] - 180s 180us/step - loss: 3.8652 - acc: 0.1288 - val_loss: 3.7874 - val_acc: 0.1396\n",
      "Epoch 13/40\n",
      "1000000/1000000 [==============================] - 180s 180us/step - loss: 3.8606 - acc: 0.1292 - val_loss: 3.7816 - val_acc: 0.1403\n",
      "Epoch 14/40\n",
      "1000000/1000000 [==============================] - 181s 181us/step - loss: 3.8561 - acc: 0.1306 - val_loss: 3.7760 - val_acc: 0.1412\n",
      "Epoch 15/40\n",
      "1000000/1000000 [==============================] - 182s 182us/step - loss: 3.8520 - acc: 0.1310 - val_loss: 3.7732 - val_acc: 0.1425\n",
      "Epoch 16/40\n",
      "1000000/1000000 [==============================] - 186s 186us/step - loss: 3.8487 - acc: 0.1316 - val_loss: 3.7684 - val_acc: 0.1426\n",
      "Epoch 17/40\n",
      "1000000/1000000 [==============================] - 186s 186us/step - loss: 3.8452 - acc: 0.1322 - val_loss: 3.7662 - val_acc: 0.1437\n",
      "Epoch 18/40\n",
      "1000000/1000000 [==============================] - 182s 182us/step - loss: 3.8410 - acc: 0.1332 - val_loss: 3.7633 - val_acc: 0.1435\n",
      "Epoch 19/40\n",
      "1000000/1000000 [==============================] - 169s 169us/step - loss: 3.8383 - acc: 0.1338 - val_loss: 3.7615 - val_acc: 0.1447\n",
      "Epoch 20/40\n",
      "1000000/1000000 [==============================] - 177s 177us/step - loss: 3.8347 - acc: 0.1344 - val_loss: 3.7594 - val_acc: 0.1449\n",
      "Epoch 21/40\n",
      "1000000/1000000 [==============================] - 176s 176us/step - loss: 3.8317 - acc: 0.1349 - val_loss: 3.7560 - val_acc: 0.1463\n",
      "Epoch 22/40\n",
      "1000000/1000000 [==============================] - 178s 178us/step - loss: 3.8296 - acc: 0.1356 - val_loss: 3.7551 - val_acc: 0.1462\n",
      "Epoch 23/40\n",
      "1000000/1000000 [==============================] - 178s 178us/step - loss: 3.8268 - acc: 0.1362 - val_loss: 3.7508 - val_acc: 0.1470\n",
      "Epoch 24/40\n",
      "1000000/1000000 [==============================] - 177s 177us/step - loss: 3.8244 - acc: 0.1365 - val_loss: 3.7499 - val_acc: 0.1466\n",
      "Epoch 25/40\n",
      "1000000/1000000 [==============================] - 175s 175us/step - loss: 3.8225 - acc: 0.1368 - val_loss: 3.7445 - val_acc: 0.1479\n",
      "Epoch 26/40\n",
      "1000000/1000000 [==============================] - 175s 175us/step - loss: 3.8205 - acc: 0.1371 - val_loss: 3.7461 - val_acc: 0.1483\n",
      "Epoch 27/40\n",
      "1000000/1000000 [==============================] - 175s 175us/step - loss: 3.8173 - acc: 0.1378 - val_loss: 3.7411 - val_acc: 0.1489\n",
      "Epoch 28/40\n",
      "1000000/1000000 [==============================] - 176s 176us/step - loss: 3.8163 - acc: 0.1381 - val_loss: 3.7374 - val_acc: 0.1494\n",
      "Epoch 29/40\n",
      "1000000/1000000 [==============================] - 177s 177us/step - loss: 3.8138 - acc: 0.1387 - val_loss: 3.7367 - val_acc: 0.1499\n",
      "Epoch 30/40\n",
      "1000000/1000000 [==============================] - 178s 178us/step - loss: 3.8121 - acc: 0.1394 - val_loss: 3.7363 - val_acc: 0.1498\n",
      "Epoch 31/40\n",
      "1000000/1000000 [==============================] - 178s 178us/step - loss: 3.8100 - acc: 0.1392 - val_loss: 3.7351 - val_acc: 0.1506\n",
      "Epoch 32/40\n",
      "1000000/1000000 [==============================] - 180s 180us/step - loss: 3.8078 - acc: 0.1399 - val_loss: 3.7331 - val_acc: 0.1505\n",
      "Epoch 33/40\n",
      "1000000/1000000 [==============================] - 179s 179us/step - loss: 3.8063 - acc: 0.1404 - val_loss: 3.7320 - val_acc: 0.1508\n",
      "Epoch 34/40\n",
      "1000000/1000000 [==============================] - 180s 180us/step - loss: 3.8045 - acc: 0.1406 - val_loss: 3.7296 - val_acc: 0.1516\n",
      "Epoch 35/40\n",
      "1000000/1000000 [==============================] - 185s 185us/step - loss: 3.8027 - acc: 0.1412 - val_loss: 3.7285 - val_acc: 0.1523\n",
      "Epoch 36/40\n",
      "1000000/1000000 [==============================] - 180s 180us/step - loss: 3.8002 - acc: 0.1417 - val_loss: 3.7272 - val_acc: 0.1522\n",
      "Epoch 37/40\n",
      "1000000/1000000 [==============================] - 186s 186us/step - loss: 3.7985 - acc: 0.1419 - val_loss: 3.7242 - val_acc: 0.1528\n",
      "Epoch 38/40\n",
      "1000000/1000000 [==============================] - 185s 185us/step - loss: 3.7971 - acc: 0.1422 - val_loss: 3.7233 - val_acc: 0.1532\n",
      "Epoch 39/40\n",
      "1000000/1000000 [==============================] - 185s 185us/step - loss: 3.7955 - acc: 0.1424 - val_loss: 3.7216 - val_acc: 0.1527\n",
      "Epoch 40/40\n",
      "1000000/1000000 [==============================] - 186s 186us/step - loss: 3.7947 - acc: 0.1427 - val_loss: 3.7252 - val_acc: 0.1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c34440b8>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "max_features = 20\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "\n",
    "batch_size = 1024*2\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "# model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=40,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(\"/Users/weilu/Research/optimization/fragment/feather_cluster_data.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>dd</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>0</td>\n",
       "      <td>DKLKKAIVQ</td>\n",
       "      <td>9,13,11,15,15,19,9,9,13,15,17,5,9,11,15,9,13,1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>1</td>\n",
       "      <td>KLKKAIVQV</td>\n",
       "      <td>9,9,13,15,17,21,5,9,11,15,17,9,13,15,19,9,13,1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>2</td>\n",
       "      <td>LKKAIVQVE</td>\n",
       "      <td>5,9,11,15,17,21,9,13,15,19,23,9,13,17,19,9,13,...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>3</td>\n",
       "      <td>KKAIVQVEH</td>\n",
       "      <td>9,13,15,19,23,25,9,13,17,19,21,9,13,17,19,9,13...</td>\n",
       "      <td>9987</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>4</td>\n",
       "      <td>KAIVQVEHD</td>\n",
       "      <td>9,13,17,19,21,25,9,13,17,19,23,9,13,15,19,11,1...</td>\n",
       "      <td>6835</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pdb  i        seq                                                 dd  \\\n",
       "0  1igqB00  0  DKLKKAIVQ  9,13,11,15,15,19,9,9,13,15,17,5,9,11,15,9,13,1...   \n",
       "1  1igqB00  1  KLKKAIVQV  9,9,13,15,17,21,5,9,11,15,17,9,13,15,19,9,13,1...   \n",
       "2  1igqB00  2  LKKAIVQVE  5,9,11,15,17,21,9,13,15,19,23,9,13,17,19,9,13,...   \n",
       "3  1igqB00  3  KKAIVQVEH  9,13,15,19,23,25,9,13,17,19,21,9,13,17,19,9,13...   \n",
       "4  1igqB00  4  KAIVQVEHD  9,13,17,19,21,25,9,13,17,19,23,9,13,15,19,11,1...   \n",
       "\n",
       "   category  count  s1  s2  s3  s4  s5  s6  s7  s8  s9  \n",
       "0        -1     -1   2   8   9   8   8   0   7  17  13  \n",
       "1        -1     -1   8   9   8   8   0   7  17  13  17  \n",
       "2        -1     -1   9   8   8   0   7  17  13  17   3  \n",
       "3      9987     13   8   8   0   7  17  13  17   3   6  \n",
       "4      6835     18   8   0   7  17  13  17   3   6   2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5,7,9,9,11,13,5,7,9,9,11,5,7,9,9,5,7,9,5,7,5                    39130\n",
       "5,7,9,11,11,13,5,7,9,9,11,5,7,9,9,5,7,9,5,7,5                   20575\n",
       "5,7,9,9,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5                   18996\n",
       "5,7,9,9,11,13,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5                   18382\n",
       "5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5                  14304\n",
       "5,7,9,9,11,13,5,7,9,11,11,5,7,9,11,5,7,9,5,7,5                  12961\n",
       "5,7,9,11,11,13,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5                  12641\n",
       "5,7,9,11,11,13,5,7,9,11,11,5,7,9,11,5,7,9,5,7,5                 12033\n",
       "5,7,9,9,11,13,5,7,9,9,11,5,5,9,9,5,7,9,5,7,5                     7326\n",
       "5,7,9,9,11,13,5,7,9,11,11,5,5,9,9,5,7,9,5,7,5                    6656\n",
       "5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5                    5374\n",
       "5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5                     5195\n",
       "5,7,9,9,11,13,5,7,9,9,11,5,7,9,9,5,5,9,5,7,5                     4941\n",
       "5,7,9,9,11,13,5,7,9,9,11,5,7,9,9,5,7,9,5,5,5                     4867\n",
       "5,7,9,9,11,13,5,7,9,9,11,5,7,9,11,5,5,9,5,7,5                    4800\n",
       "5,7,9,11,11,13,5,7,9,9,11,5,7,9,9,5,7,9,5,5,5                    4735\n",
       "5,7,9,11,11,13,5,5,9,9,11,5,7,9,11,5,7,9,5,7,5                   4654\n",
       "5,5,9,9,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5                    4367\n",
       "5,5,9,9,11,13,5,7,9,9,11,5,7,9,9,5,7,9,5,7,5                     4213\n",
       "5,5,9,9,11,13,5,7,9,11,11,5,7,9,11,5,7,9,5,7,5                   3600\n",
       "5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,5,9,5,7,5                   3426\n",
       "5,7,9,9,11,13,5,5,9,9,11,5,7,9,11,5,7,9,5,7,5                    3236\n",
       "5,7,9,9,11,13,5,5,9,9,11,5,5,9,9,5,7,9,5,7,5                     3225\n",
       "5,7,9,11,11,13,5,7,9,11,11,5,7,9,9,5,7,9,5,5,5                   3170\n",
       "5,7,9,9,11,13,5,7,9,9,11,5,5,9,9,5,5,9,5,7,5                     3071\n",
       "5,7,9,11,11,13,5,7,9,9,11,5,7,9,9,5,5,9,5,7,5                    2981\n",
       "5,7,9,11,11,13,5,7,9,11,11,5,5,9,9,5,7,9,5,7,5                   2898\n",
       "5,7,9,9,11,13,5,7,9,11,11,5,7,9,9,5,7,9,5,5,5                    2779\n",
       "5,5,9,9,11,13,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5                    2671\n",
       "9,7,7,11,11,11,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5                   2452\n",
       "                                                                ...  \n",
       "5,9,11,11,15,17,9,9,11,15,17,5,9,11,15,7,9,13,7,11,11               1\n",
       "11,11,9,7,9,13,9,7,5,5,9,5,5,5,9,7,5,7,7,9,9                        1\n",
       "7,9,9,11,9,5,9,11,11,9,7,9,11,9,7,7,5,7,5,7,5                       1\n",
       "5,7,11,13,11,13,5,7,11,9,11,7,11,11,13,9,9,13,5,9,9                 1\n",
       "5,7,9,11,11,9,9,11,13,13,11,9,11,11,9,9,7,7,5,7,5                   1\n",
       "9,13,11,11,13,9,9,7,7,9,7,5,7,9,7,7,11,9,9,9,5                      1\n",
       "9,11,15,13,17,15,9,11,9,13,11,9,7,11,9,5,9,9,9,7,5                  1\n",
       "11,13,15,17,21,21,9,13,15,19,19,9,13,17,19,11,13,17,11,13,11        1\n",
       "9,11,11,13,15,15,9,9,13,13,11,5,9,9,9,9,11,7,9,7,5                  1\n",
       "7,9,13,15,19,19,11,13,17,19,21,9,13,17,17,9,13,15,11,11,9           1\n",
       "7,9,11,15,17,17,9,11,13,17,17,9,11,13,13,9,11,13,9,11,7             1\n",
       "5,9,11,13,13,17,9,11,11,13,15,9,11,11,15,7,9,11,5,9,7               1\n",
       "9,13,15,15,17,15,9,13,13,15,15,9,11,13,11,9,11,9,9,7,5              1\n",
       "5,7,9,11,13,11,5,9,11,11,9,7,9,11,9,9,11,11,9,9,9                   1\n",
       "9,11,15,17,17,17,11,13,15,15,17,9,11,11,13,9,9,13,5,9,9             1\n",
       "7,9,13,13,13,17,9,13,13,13,17,9,9,9,13,5,7,11,5,7,7                 1\n",
       "7,9,9,13,17,19,7,11,15,17,19,11,13,15,17,11,13,15,9,11,11           1\n",
       "5,9,9,9,11,13,9,9,11,13,15,5,7,11,11,5,7,11,5,7,5                   1\n",
       "9,11,13,15,19,23,7,9,11,15,19,11,13,17,19,9,13,15,9,13,9            1\n",
       "5,7,9,9,13,15,5,7,9,11,13,5,5,7,9,5,9,9,9,11,9                      1\n",
       "5,7,9,11,15,17,5,7,11,15,15,5,9,11,13,7,11,13,11,11,9               1\n",
       "9,11,15,19,21,23,9,11,15,17,19,9,13,17,17,9,13,15,11,11,9           1\n",
       "9,11,11,15,15,17,7,9,11,13,15,9,13,15,17,9,13,17,11,13,11           1\n",
       "11,13,17,21,21,23,9,13,17,17,21,9,13,13,17,11,11,15,9,13,11         1\n",
       "7,11,13,13,15,11,9,11,13,13,11,9,11,11,7,7,9,5,7,5,5                1\n",
       "7,9,11,11,9,11,9,11,9,9,13,9,5,7,11,5,7,11,5,7,7                    1\n",
       "5,7,7,11,11,9,7,9,11,13,11,9,11,11,9,7,7,7,7,9,7                    1\n",
       "9,11,11,13,13,11,9,11,13,15,13,7,9,11,11,9,13,11,9,9,9              1\n",
       "9,9,11,13,17,17,7,9,13,15,17,9,11,13,15,7,11,13,11,13,9             1\n",
       "5,7,11,13,13,11,5,9,13,13,11,7,11,11,11,9,7,7,9,7,5                 1\n",
       "Name: dd, Length: 853589, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dd\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5195, 15)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query(\"category == 11\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cat 10 and 11 are very similar. they should be in the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>dd</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299936</th>\n",
       "      <td>3tulA00</td>\n",
       "      <td>66</td>\n",
       "      <td>AKSVYDAAT</td>\n",
       "      <td>5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>10</td>\n",
       "      <td>5374</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876837</th>\n",
       "      <td>1k1fA00</td>\n",
       "      <td>27</td>\n",
       "      <td>DIEQELERA</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418011</th>\n",
       "      <td>1ztpA01</td>\n",
       "      <td>107</td>\n",
       "      <td>AWAGIARAV</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211494</th>\n",
       "      <td>3zkvA00</td>\n",
       "      <td>758</td>\n",
       "      <td>QFLTHFVMQ</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313392</th>\n",
       "      <td>1pp1X01</td>\n",
       "      <td>110</td>\n",
       "      <td>HCCSLLIGV</td>\n",
       "      <td>5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>10</td>\n",
       "      <td>5374</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429159</th>\n",
       "      <td>2j7qA00</td>\n",
       "      <td>169</td>\n",
       "      <td>DFTEAISAL</td>\n",
       "      <td>5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>10</td>\n",
       "      <td>5374</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323194</th>\n",
       "      <td>1s7oB00</td>\n",
       "      <td>96</td>\n",
       "      <td>KISILTSID</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192023</th>\n",
       "      <td>2pftA00</td>\n",
       "      <td>27</td>\n",
       "      <td>YLGSMAKIQ</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204807</th>\n",
       "      <td>4f3qA01</td>\n",
       "      <td>7</td>\n",
       "      <td>AKARQDAKR</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324321</th>\n",
       "      <td>3aqpA02</td>\n",
       "      <td>21</td>\n",
       "      <td>LEKARTVLE</td>\n",
       "      <td>5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>10</td>\n",
       "      <td>5374</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pdb    i        seq  \\\n",
       "299936   3tulA00   66  AKSVYDAAT   \n",
       "1876837  1k1fA00   27  DIEQELERA   \n",
       "418011   1ztpA01  107  AWAGIARAV   \n",
       "1211494  3zkvA00  758  QFLTHFVMQ   \n",
       "313392   1pp1X01  110  HCCSLLIGV   \n",
       "429159   2j7qA00  169  DFTEAISAL   \n",
       "1323194  1s7oB00   96  KISILTSID   \n",
       "192023   2pftA00   27  YLGSMAKIQ   \n",
       "1204807  4f3qA01    7  AKARQDAKR   \n",
       "1324321  3aqpA02   21  LEKARTVLE   \n",
       "\n",
       "                                                    dd  category  count  s1  \\\n",
       "299936   5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        10   5374   0   \n",
       "1876837   5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   2   \n",
       "418011    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   0   \n",
       "1211494   5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195  13   \n",
       "313392   5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        10   5374   6   \n",
       "429159   5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        10   5374   2   \n",
       "1323194   5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   8   \n",
       "192023    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195  19   \n",
       "1204807   5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   0   \n",
       "1324321  5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        10   5374   9   \n",
       "\n",
       "         s2  s3  s4  s5  s6  s7  s8  s9  \n",
       "299936    8  15  17  19   2   0   0  16  \n",
       "1876837   7   3  13   3   9   3  14   0  \n",
       "418011   18   0   5   7   0  14   0  17  \n",
       "1211494   4   9  16   6   4  17  10  13  \n",
       "313392    1   1  15   9   9   7   5  17  \n",
       "429159    4  16   3   0   7  15   0   9  \n",
       "1323194   7  15   7   9  16  15   7   2  \n",
       "192023    9   5  15  10   0   8   7  13  \n",
       "1204807   8   0  14  13   2   0   8  14  \n",
       "1324321   3   8   0  14  16  17   9   3  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query(\"category == 10 or category == 11\").sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>dd</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1211147</th>\n",
       "      <td>3zkvA00</td>\n",
       "      <td>395</td>\n",
       "      <td>LEACIYSFQ</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711744</th>\n",
       "      <td>2itbA00</td>\n",
       "      <td>36</td>\n",
       "      <td>FKAASTALS</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413878</th>\n",
       "      <td>3rjvA01</td>\n",
       "      <td>15</td>\n",
       "      <td>RAQYYLADT</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836419</th>\n",
       "      <td>5tkyA03</td>\n",
       "      <td>30</td>\n",
       "      <td>ALRRLRTAC</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216811</th>\n",
       "      <td>1w9cA00</td>\n",
       "      <td>141</td>\n",
       "      <td>FFLLLQAVN</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249112</th>\n",
       "      <td>1ej6B00</td>\n",
       "      <td>233</td>\n",
       "      <td>INPTEIEWA</td>\n",
       "      <td>9,7,7,11,11,11,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>29</td>\n",
       "      <td>2452</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664651</th>\n",
       "      <td>2qtfA01</td>\n",
       "      <td>42</td>\n",
       "      <td>IQYDKLQQI</td>\n",
       "      <td>9,7,7,11,11,11,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>29</td>\n",
       "      <td>2452</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950129</th>\n",
       "      <td>1xflA00</td>\n",
       "      <td>46</td>\n",
       "      <td>APFFADLAK</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310748</th>\n",
       "      <td>2yyuB00</td>\n",
       "      <td>138</td>\n",
       "      <td>VETVAHYAA</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822123</th>\n",
       "      <td>3qvsA01</td>\n",
       "      <td>236</td>\n",
       "      <td>PLILDIARF</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pdb    i        seq  \\\n",
       "1211147  3zkvA00  395  LEACIYSFQ   \n",
       "1711744  2itbA00   36  FKAASTALS   \n",
       "413878   3rjvA01   15  RAQYYLADT   \n",
       "1836419  5tkyA03   30  ALRRLRTAC   \n",
       "1216811  1w9cA00  141  FFLLLQAVN   \n",
       "249112   1ej6B00  233  INPTEIEWA   \n",
       "1664651  2qtfA01   42  IQYDKLQQI   \n",
       "950129   1xflA00   46  APFFADLAK   \n",
       "310748   2yyuB00  138  VETVAHYAA   \n",
       "822123   3qvsA01  236  PLILDIARF   \n",
       "\n",
       "                                                     dd  category  count  s1  \\\n",
       "1211147    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   9   \n",
       "1711744    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   4   \n",
       "413878     5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195  14   \n",
       "1836419    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   0   \n",
       "1216811    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   4   \n",
       "249112   9,7,7,11,11,11,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5        29   2452   7   \n",
       "1664651  9,7,7,11,11,11,5,7,9,11,11,5,7,9,9,5,7,9,5,7,5        29   2452   7   \n",
       "950129     5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   0   \n",
       "310748     5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195  17   \n",
       "822123     5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195  12   \n",
       "\n",
       "         s2  s3  s4  s5  s6  s7  s8  s9  \n",
       "1211147   3   0   1   7  19  15   4  13  \n",
       "1711744   8   0   0  15  16   0   9  15  \n",
       "413878    0  13  19  19   9   0   2  16  \n",
       "1836419   9  14  14   9  14  16   0   1  \n",
       "1216811   4   9   9   9  13   0  17  11  \n",
       "249112   11  12  16   3   7   3  18   0  \n",
       "1664651  13  19   2   8   9  13  13   7  \n",
       "950129   12   4   4   0   2   9   0   8  \n",
       "310748    3  16  17   0   6  19   0   0  \n",
       "822123    9   7   9   2   7   0  14   4  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query(\"category == 29 or category == 11\").sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>dd</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1691660</th>\n",
       "      <td>3ar4A04</td>\n",
       "      <td>179</td>\n",
       "      <td>TGPVKEKIL</td>\n",
       "      <td>5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5</td>\n",
       "      <td>4</td>\n",
       "      <td>14304</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606678</th>\n",
       "      <td>4fguB02</td>\n",
       "      <td>2</td>\n",
       "      <td>DVPLTIMKR</td>\n",
       "      <td>5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5</td>\n",
       "      <td>4</td>\n",
       "      <td>14304</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297613</th>\n",
       "      <td>4muoA02</td>\n",
       "      <td>229</td>\n",
       "      <td>GLARVNQAF</td>\n",
       "      <td>5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5</td>\n",
       "      <td>4</td>\n",
       "      <td>14304</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395061</th>\n",
       "      <td>5aj3P00</td>\n",
       "      <td>95</td>\n",
       "      <td>TNAERLRRK</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029953</th>\n",
       "      <td>2oryA00</td>\n",
       "      <td>207</td>\n",
       "      <td>NADFADYFD</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765556</th>\n",
       "      <td>1zhcA00</td>\n",
       "      <td>45</td>\n",
       "      <td>VSHMKKQKL</td>\n",
       "      <td>5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5</td>\n",
       "      <td>4</td>\n",
       "      <td>14304</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755750</th>\n",
       "      <td>4i9cA02</td>\n",
       "      <td>181</td>\n",
       "      <td>DLEDFAIDV</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486275</th>\n",
       "      <td>1h9eA00</td>\n",
       "      <td>14</td>\n",
       "      <td>LKSELVANN</td>\n",
       "      <td>5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5</td>\n",
       "      <td>4</td>\n",
       "      <td>14304</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200946</th>\n",
       "      <td>3s1sA02</td>\n",
       "      <td>125</td>\n",
       "      <td>DIELGKVLS</td>\n",
       "      <td>5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5</td>\n",
       "      <td>4</td>\n",
       "      <td>14304</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072383</th>\n",
       "      <td>3it4B01</td>\n",
       "      <td>56</td>\n",
       "      <td>AQADLDEAV</td>\n",
       "      <td>5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5</td>\n",
       "      <td>4</td>\n",
       "      <td>14304</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pdb    i        seq  \\\n",
       "1691660  3ar4A04  179  TGPVKEKIL   \n",
       "606678   4fguB02    2  DVPLTIMKR   \n",
       "1297613  4muoA02  229  GLARVNQAF   \n",
       "395061   5aj3P00   95  TNAERLRRK   \n",
       "1029953  2oryA00  207  NADFADYFD   \n",
       "1765556  1zhcA00   45  VSHMKKQKL   \n",
       "755750   4i9cA02  181  DLEDFAIDV   \n",
       "1486275  1h9eA00   14  LKSELVANN   \n",
       "1200946  3s1sA02  125  DIELGKVLS   \n",
       "1072383  3it4B01   56  AQADLDEAV   \n",
       "\n",
       "                                                     dd  category  count  s1  \\\n",
       "1691660  5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5         4  14304  16   \n",
       "606678   5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5         4  14304   2   \n",
       "1297613  5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5         4  14304   5   \n",
       "395061     5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195  16   \n",
       "1029953    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195  11   \n",
       "1765556  5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5         4  14304  17   \n",
       "755750     5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   2   \n",
       "1486275  5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5         4  14304   9   \n",
       "1200946  5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5         4  14304   2   \n",
       "1072383  5,7,9,11,11,13,5,7,9,9,11,5,7,9,11,5,7,9,5,7,5         4  14304   0   \n",
       "\n",
       "         s2  s3  s4  s5  s6  s7  s8  s9  \n",
       "1691660   5  12  17   8   3   8   7   9  \n",
       "606678   17  12   9  16   7  10   8  14  \n",
       "1297613   9   0  14  17  11  13   0   4  \n",
       "395061   11   0   3  14   9  14  14   8  \n",
       "1029953   0   2   4   0   2  19   4   2  \n",
       "1765556  15   6  10   8   8  13   8   9  \n",
       "755750    9   3   2   4   0   7   2  17  \n",
       "1486275   8  15   3   9  17   0  11  11  \n",
       "1200946   7   3   9   5   8  17   9  15  \n",
       "1072383  13   0   2   9   2   3   0  17  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query(\"category == 4 or category == 11\").sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>dd</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>929058</th>\n",
       "      <td>3i4rB00</td>\n",
       "      <td>40</td>\n",
       "      <td>DRAVTQISV</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276353</th>\n",
       "      <td>4tl2A02</td>\n",
       "      <td>72</td>\n",
       "      <td>DWHDLAAFW</td>\n",
       "      <td>5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>10</td>\n",
       "      <td>5374</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869288</th>\n",
       "      <td>1xdpA01</td>\n",
       "      <td>31</td>\n",
       "      <td>GIYSNNLDE</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358821</th>\n",
       "      <td>2g7lA00</td>\n",
       "      <td>132</td>\n",
       "      <td>LQDATATAA</td>\n",
       "      <td>5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>10</td>\n",
       "      <td>5374</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857911</th>\n",
       "      <td>2jbrA03</td>\n",
       "      <td>83</td>\n",
       "      <td>ARALLEKTW</td>\n",
       "      <td>5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5</td>\n",
       "      <td>11</td>\n",
       "      <td>5195</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pdb    i        seq  \\\n",
       "929058   3i4rB00   40  DRAVTQISV   \n",
       "1276353  4tl2A02   72  DWHDLAAFW   \n",
       "869288   1xdpA01   31  GIYSNNLDE   \n",
       "1358821  2g7lA00  132  LQDATATAA   \n",
       "857911   2jbrA03   83  ARALLEKTW   \n",
       "\n",
       "                                                    dd  category  count  s1  \\\n",
       "929058    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   2   \n",
       "1276353  5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        10   5374   2   \n",
       "869288    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   5   \n",
       "1358821  5,7,9,11,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        10   5374   9   \n",
       "857911    5,7,9,9,11,13,5,5,9,9,11,5,7,9,9,5,7,9,5,7,5        11   5195   0   \n",
       "\n",
       "         s2  s3  s4  s5  s6  s7  s8  s9  \n",
       "929058   14   0  17  16  13   7  15  17  \n",
       "1276353  18   6   2   9   0   0   4  18  \n",
       "869288    7  19  15  11  11   9   2   3  \n",
       "1358821  13   2   0  16   0  16   0   0  \n",
       "857911   14   0   9   9   3   8  16  18  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6656, 15)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query(\"category == 9\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (100000, 9)\n"
     ]
    }
   ],
   "source": [
    "test = data.query(\"category > -1 and category < 10\").groupby(\"category\").apply(pd.DataFrame.sample, 10000, replace=True)\n",
    "# test = data.query(\"category > -1 and category < 10\").sample(10000)\n",
    "x_train = test.iloc[:, 6:15].values\n",
    "y_train_value = test[\"category\"].values\n",
    "test = data.query(\"category > -1 and category < 10\").groupby(\"category\").apply(pd.DataFrame.sample, 10000, replace=True)\n",
    "# test = data.query(\"category > -1 and category < 10\").sample(10000)\n",
    "x_test = test.iloc[:, 6:15].values\n",
    "y_test_value = test[\"category\"].values\n",
    "\n",
    "# print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "y_train = to_categorical(np.array(y_train_value))\n",
    "y_test = to_categorical(np.array(y_test_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10000., 10000., 10000., 10000., 10000., 10000., 10000., 10000.,\n",
       "       10000., 10000.], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 train sequences\n",
      "Train...\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 116s 1ms/step - loss: 2.2778 - acc: 0.1338 - val_loss: 2.2583 - val_acc: 0.1490\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 107s 1ms/step - loss: 2.2539 - acc: 0.1527 - val_loss: 2.2470 - val_acc: 0.1550\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 107s 1ms/step - loss: 2.2460 - acc: 0.1573 - val_loss: 2.2391 - val_acc: 0.1637\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 108s 1ms/step - loss: 2.2376 - acc: 0.1638 - val_loss: 2.2305 - val_acc: 0.1668\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 117s 1ms/step - loss: 2.2283 - acc: 0.1683 - val_loss: 2.2232 - val_acc: 0.1720\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 108s 1ms/step - loss: 2.2173 - acc: 0.1771 - val_loss: 2.2177 - val_acc: 0.1788\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 108s 1ms/step - loss: 2.2060 - acc: 0.1819 - val_loss: 2.2097 - val_acc: 0.1814\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 108s 1ms/step - loss: 2.1924 - acc: 0.1889 - val_loss: 2.2030 - val_acc: 0.1861\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 108s 1ms/step - loss: 2.1748 - acc: 0.1985 - val_loss: 2.1945 - val_acc: 0.1907\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 113s 1ms/step - loss: 2.1579 - acc: 0.2080 - val_loss: 2.1833 - val_acc: 0.1987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x192d892b0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "max_features = 20000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 9\n",
    "batch_size = 32\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "# model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=40,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/2\n",
      "100000/100000 [==============================] - 18s 183us/step - loss: 1.7636 - acc: 0.3695 - val_loss: 2.0681 - val_acc: 0.2857\n",
      "Epoch 2/2\n",
      "100000/100000 [==============================] - 18s 176us/step - loss: 1.7558 - acc: 0.3744 - val_loss: 2.0647 - val_acc: 0.2868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5e005c0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=10240,\n",
    "          epochs=2,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1152,  964, 1188, 1183,  896,  947,  895,  789, 1236,  750],\n",
       "       [ 912, 1745,  802,  828, 1418,  633, 1308,  977,  861,  516],\n",
       "       [ 905,  722, 2160,  904, 1224, 1186,  572,  825,  979,  523],\n",
       "       [ 859,  633,  823, 2042,  660, 1214, 1071,  865,  876,  957],\n",
       "       [ 599, 1074, 1174,  536, 2915,  735,  837, 1127,  640,  363],\n",
       "       [ 701,  367, 1100, 1265,  719, 2588,  725, 1062,  744,  729],\n",
       "       [ 597, 1088,  474, 1141,  808,  690, 2615, 1361,  658,  568],\n",
       "       [ 495,  690,  727,  729, 1215, 1004, 1155, 2928,  547,  510],\n",
       "       [ 577,  407,  652,  559,  355,  533,  348,  337, 5154, 1078],\n",
       "       [ 336,  201,  380,  794,  187,  586,  454,  370, 1308, 5384]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "predicted = np.argmax(y_pred, axis=1)\n",
    "confusion_matrix(y_test_value, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107, 102, 141, 114,  57, 104,  74,  73, 138,  90],\n",
       "       [ 82, 123,  97,  81, 108, 102, 100, 111, 118,  78],\n",
       "       [ 88, 102, 133,  79,  88, 129,  48,  93, 123, 117],\n",
       "       [ 81,  91, 122, 133,  68, 143,  87,  77,  97, 101],\n",
       "       [ 66, 121, 128,  87, 114, 109,  80, 116, 105,  74],\n",
       "       [ 89,  87, 115, 132,  72, 137,  71,  88, 109, 100],\n",
       "       [ 70, 125,  94, 114, 113, 115, 107, 106,  89,  67],\n",
       "       [ 64, 102, 119, 110, 105, 131,  94, 109,  86,  80],\n",
       "       [ 96,  86, 124,  69,  66, 103,  40,  77, 219, 120],\n",
       "       [ 82,  71, 126, 110,  61, 140,  45,  85, 128, 152]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_value, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2327., 1264., 1173., 1126.,  918.,  839.,  789.,  724.,  446.,\n",
       "        394.], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 train sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (1000, 9)\n",
      "Train...\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6922 - acc: 0.5350 - val_loss: 0.6884 - val_acc: 0.5350\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6875 - acc: 0.5500 - val_loss: 0.6816 - val_acc: 0.5980\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6810 - acc: 0.5840 - val_loss: 0.6734 - val_acc: 0.5810\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6768 - acc: 0.5630 - val_loss: 0.6698 - val_acc: 0.6030\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6679 - acc: 0.5940 - val_loss: 0.6592 - val_acc: 0.6030\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6623 - acc: 0.6020 - val_loss: 0.6546 - val_acc: 0.6100\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6570 - acc: 0.6090 - val_loss: 0.6504 - val_acc: 0.6180\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6569 - acc: 0.6080 - val_loss: 0.6492 - val_acc: 0.6120\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6554 - acc: 0.6130 - val_loss: 0.6447 - val_acc: 0.6150\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6488 - acc: 0.6150 - val_loss: 0.6462 - val_acc: 0.6300\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6467 - acc: 0.6280 - val_loss: 0.6388 - val_acc: 0.6190\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6450 - acc: 0.6130 - val_loss: 0.6339 - val_acc: 0.6210\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6444 - acc: 0.6250 - val_loss: 0.6289 - val_acc: 0.6300\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6347 - acc: 0.6230 - val_loss: 0.6256 - val_acc: 0.6320\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6363 - acc: 0.6310 - val_loss: 0.6226 - val_acc: 0.6390\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6333 - acc: 0.6280 - val_loss: 0.6233 - val_acc: 0.6400\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6294 - acc: 0.6280 - val_loss: 0.6164 - val_acc: 0.6430\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6281 - acc: 0.6360 - val_loss: 0.6119 - val_acc: 0.6510\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6159 - acc: 0.6440 - val_loss: 0.6100 - val_acc: 0.6500\n",
      "Epoch 20/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6204 - acc: 0.6440 - val_loss: 0.6064 - val_acc: 0.6640\n",
      "Epoch 21/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6137 - acc: 0.6510 - val_loss: 0.5981 - val_acc: 0.6720\n",
      "Epoch 22/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6029 - acc: 0.6650 - val_loss: 0.6042 - val_acc: 0.6740\n",
      "Epoch 23/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6011 - acc: 0.6570 - val_loss: 0.5867 - val_acc: 0.6880\n",
      "Epoch 24/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6029 - acc: 0.6660 - val_loss: 0.5810 - val_acc: 0.6800\n",
      "Epoch 25/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5945 - acc: 0.6680 - val_loss: 0.5717 - val_acc: 0.6830\n",
      "Epoch 26/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5866 - acc: 0.6730 - val_loss: 0.5715 - val_acc: 0.6930\n",
      "Epoch 27/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5787 - acc: 0.6860 - val_loss: 0.5592 - val_acc: 0.7060\n",
      "Epoch 28/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5786 - acc: 0.6810 - val_loss: 0.5499 - val_acc: 0.7150\n",
      "Epoch 29/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5653 - acc: 0.6930 - val_loss: 0.5393 - val_acc: 0.7250\n",
      "Epoch 30/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5626 - acc: 0.7070 - val_loss: 0.5420 - val_acc: 0.7310\n",
      "Epoch 31/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5627 - acc: 0.6910 - val_loss: 0.5292 - val_acc: 0.7230\n",
      "Epoch 32/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5412 - acc: 0.7140 - val_loss: 0.5129 - val_acc: 0.7360\n",
      "Epoch 33/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5381 - acc: 0.7130 - val_loss: 0.4962 - val_acc: 0.7400\n",
      "Epoch 34/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5263 - acc: 0.7250 - val_loss: 0.5032 - val_acc: 0.7510\n",
      "Epoch 35/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5227 - acc: 0.7290 - val_loss: 0.4846 - val_acc: 0.7590\n",
      "Epoch 36/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5069 - acc: 0.7220 - val_loss: 0.4678 - val_acc: 0.7650\n",
      "Epoch 37/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4847 - acc: 0.7540 - val_loss: 0.4518 - val_acc: 0.7790\n",
      "Epoch 38/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4756 - acc: 0.7510 - val_loss: 0.4586 - val_acc: 0.7650\n",
      "Epoch 39/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4926 - acc: 0.7450 - val_loss: 0.4354 - val_acc: 0.7820\n",
      "Epoch 40/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4866 - acc: 0.7470 - val_loss: 0.4413 - val_acc: 0.7820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a19d860>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 9\n",
    "batch_size = 32\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=40,\n",
    "          validation_data=[x_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 98s 4ms/step - loss: 0.4393 - acc: 0.7982 - val_loss: 0.3589 - val_acc: 0.8412\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.2482 - acc: 0.9024 - val_loss: 0.4077 - val_acc: 0.8422\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.1685 - acc: 0.9390 - val_loss: 0.4364 - val_acc: 0.8392\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 98s 4ms/step - loss: 0.1138 - acc: 0.9591 - val_loss: 0.5522 - val_acc: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c087e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=4,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>i</th>\n",
       "      <th>seq</th>\n",
       "      <th>dd</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>0</td>\n",
       "      <td>DKLKKAIVQ</td>\n",
       "      <td>9,13,11,15,15,19,9,9,13,15,17,5,9,11,15,9,13,1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>1</td>\n",
       "      <td>KLKKAIVQV</td>\n",
       "      <td>9,9,13,15,17,21,5,9,11,15,17,9,13,15,19,9,13,1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>2</td>\n",
       "      <td>LKKAIVQVE</td>\n",
       "      <td>5,9,11,15,17,21,9,13,15,19,23,9,13,17,19,9,13,...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>3</td>\n",
       "      <td>KKAIVQVEH</td>\n",
       "      <td>9,13,15,19,23,25,9,13,17,19,21,9,13,17,19,9,13...</td>\n",
       "      <td>9987</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1igqB00</td>\n",
       "      <td>4</td>\n",
       "      <td>KAIVQVEHD</td>\n",
       "      <td>9,13,17,19,21,25,9,13,17,19,23,9,13,15,19,11,1...</td>\n",
       "      <td>6835</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pdb  i        seq                                                 dd  \\\n",
       "0  1igqB00  0  DKLKKAIVQ  9,13,11,15,15,19,9,9,13,15,17,5,9,11,15,9,13,1...   \n",
       "1  1igqB00  1  KLKKAIVQV  9,9,13,15,17,21,5,9,11,15,17,9,13,15,19,9,13,1...   \n",
       "2  1igqB00  2  LKKAIVQVE  5,9,11,15,17,21,9,13,15,19,23,9,13,17,19,9,13,...   \n",
       "3  1igqB00  3  KKAIVQVEH  9,13,15,19,23,25,9,13,17,19,21,9,13,17,19,9,13...   \n",
       "4  1igqB00  4  KAIVQVEHD  9,13,17,19,21,25,9,13,17,19,23,9,13,15,19,11,1...   \n",
       "\n",
       "   category  count  s1  s2  s3  s4  s5  s6  s7  s8  s9  \n",
       "0        -1     -1   2   8   9   8   8   0   7  17  13  \n",
       "1        -1     -1   8   9   8   8   0   7  17  13  17  \n",
       "2        -1     -1   9   8   8   0   7  17  13  17   3  \n",
       "3      9987     13   8   8   0   7  17  13  17   3   6  \n",
       "4      6835     18   8   0   7  17  13  17   3   6   2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "  416/60000 [..............................] - ETA: 15:49 - loss: 2.2967 - acc: 0.1298"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-d665489173cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Evaluation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Example of using Hierarchical RNN (HRNN) to classify MNIST digits.\n",
    "\n",
    "HRNNs can learn across multiple levels\n",
    "of temporal hierarchy over a complex sequence.\n",
    "Usually, the first recurrent layer of an HRNN\n",
    "encodes a sentence (e.g. of word vectors)\n",
    "into a  sentence vector.\n",
    "The second recurrent layer then encodes a sequence of\n",
    "such vectors (encoded by the first layer) into a document vector.\n",
    "This document vector is considered to preserve both\n",
    "the word-level and sentence-level structure of the context.\n",
    "\n",
    "# References\n",
    "\n",
    "- [A Hierarchical Neural Autoencoder for Paragraphs and Documents]\n",
    "    (https://arxiv.org/abs/1506.01057)\n",
    "    Encodes paragraphs and documents with HRNN.\n",
    "    Results have shown that HRNN outperforms standard\n",
    "    RNNs and may play some role in more sophisticated generation tasks like\n",
    "    summarization or question answering.\n",
    "- [Hierarchical recurrent neural network for skeleton based action recognition]\n",
    "    (http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298714)\n",
    "    Achieved state-of-the-art results on\n",
    "    skeleton based action recognition with 3 levels\n",
    "    of bidirectional HRNN combined with fully connected layers.\n",
    "\n",
    "In the below MNIST example the first LSTM layer first encodes every\n",
    "column of pixels of shape (28, 1) to a column vector of shape (128,).\n",
    "The second LSTM layer encodes then these 28 column vectors of shape (28, 128)\n",
    "to a image vector representing the whole image.\n",
    "A final Dense layer is added for prediction.\n",
    "\n",
    "After 5 epochs: train acc: 0.9858, val acc: 0.9864\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Training parameters.\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# Embedding dimensions.\n",
    "row_hidden = 128\n",
    "col_hidden = 128\n",
    "\n",
    "# The data, split between train and test sets.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshapes data to 4D for Hierarchical RNN.\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Converts class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "row, col, pixel = x_train.shape[1:]\n",
    "\n",
    "# 4D input.\n",
    "x = Input(shape=(row, col, pixel))\n",
    "\n",
    "# Encodes a row of pixels using TimeDistributed Wrapper.\n",
    "encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n",
    "\n",
    "# Encodes columns of encoded rows.\n",
    "encoded_columns = LSTM(col_hidden)(encoded_rows)\n",
    "\n",
    "# Final predictions and model.\n",
    "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
    "model = Model(x, prediction)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training.\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluation.\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.49411765],\n",
       "        [0.53333336],\n",
       "        [0.6862745 ],\n",
       "        [0.10196079],\n",
       "        [0.6509804 ],\n",
       "        [1.        ],\n",
       "        [0.96862745],\n",
       "        [0.49803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.14117648],\n",
       "        [0.36862746],\n",
       "        [0.6039216 ],\n",
       "        [0.6666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.88235295],\n",
       "        [0.6745098 ],\n",
       "        [0.99215686],\n",
       "        [0.9490196 ],\n",
       "        [0.7647059 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.19215687],\n",
       "        [0.93333334],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.9843137 ],\n",
       "        [0.3647059 ],\n",
       "        [0.32156864],\n",
       "        [0.32156864],\n",
       "        [0.21960784],\n",
       "        [0.15294118],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.7137255 ],\n",
       "        [0.96862745],\n",
       "        [0.94509804],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3137255 ],\n",
       "        [0.6117647 ],\n",
       "        [0.41960785],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8039216 ],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.16862746],\n",
       "        [0.6039216 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05490196],\n",
       "        [0.00392157],\n",
       "        [0.6039216 ],\n",
       "        [0.99215686],\n",
       "        [0.3529412 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.54509807],\n",
       "        [0.99215686],\n",
       "        [0.74509805],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04313726],\n",
       "        [0.74509805],\n",
       "        [0.99215686],\n",
       "        [0.27450982],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.13725491],\n",
       "        [0.94509804],\n",
       "        [0.88235295],\n",
       "        [0.627451  ],\n",
       "        [0.42352942],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.31764707],\n",
       "        [0.9411765 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.46666667],\n",
       "        [0.09803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1764706 ],\n",
       "        [0.7294118 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.5882353 ],\n",
       "        [0.10588235],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0627451 ],\n",
       "        [0.3647059 ],\n",
       "        [0.9882353 ],\n",
       "        [0.99215686],\n",
       "        [0.73333335],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.9764706 ],\n",
       "        [0.99215686],\n",
       "        [0.9764706 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.18039216],\n",
       "        [0.50980395],\n",
       "        [0.7176471 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8117647 ],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15294118],\n",
       "        [0.5803922 ],\n",
       "        [0.8980392 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.98039216],\n",
       "        [0.7137255 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09411765],\n",
       "        [0.44705883],\n",
       "        [0.8666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7882353 ],\n",
       "        [0.30588236],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09019608],\n",
       "        [0.25882354],\n",
       "        [0.8352941 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.31764707],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.67058825],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7647059 ],\n",
       "        [0.3137255 ],\n",
       "        [0.03529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568628],\n",
       "        [0.6745098 ],\n",
       "        [0.8862745 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.95686275],\n",
       "        [0.52156866],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.53333336],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.83137256],\n",
       "        [0.5294118 ],\n",
       "        [0.5176471 ],\n",
       "        [0.0627451 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
