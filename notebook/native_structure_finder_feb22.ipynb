{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_test_data = pd.read_csv(\"/Users/weilu/Research/data/test_data/test_data_4.csv\")\n",
    "raw_test_data_2 = raw_test_data.drop_duplicates(subset=['Qw', 'Rw', \"VTotal\"])\n",
    "raw_test_data_2 = raw_test_data_2.assign(isGood=raw_test_data_2.groupby(\"Name\")[\"GDT\"].rank(ascending=False) < 50)\n",
    "raw_test_data = raw_test_data_2\n",
    "raw_data_T0784 = raw_test_data.groupby(\"Name\").get_group(\"T0784\")\n",
    "raw_data_T0792 = raw_test_data.groupby(\"Name\").get_group(\"T0792\")\n",
    "# raw_data = pd.concat([raw_data_T0784, raw_data_T0792])\n",
    "raw_data = raw_data_T0792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_test_data.to_csv(\"/Users/weilu/Research/data/test_data/remove_duplicated_frame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FEATURES = [\"Rw\", \"VTotal\", \"QGO\"]\n",
    "# FEATURES = [\"Rw\", \"VTotal\", \"QGO\", \"Burial\", \"Frag_Mem\", \"Water\"]\n",
    "# FEATURES = list(raw_test_data.columns[2:-3])\n",
    "FEATURES = ['Rw',\n",
    " 'VTotal',\n",
    " 'QGO',\n",
    " 'Burial',\n",
    " 'Water',\n",
    " 'Rama',\n",
    " 'DSSP',\n",
    " 'P_AP',\n",
    " 'Helix',\n",
    " 'Frag_Mem']\n",
    "# LABEL = \"Qw\"\n",
    "LABEL = \"isGood\"\n",
    "PolynomialDegree = 2\n",
    "p = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "class RemoveFirstFrame(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, frame):\n",
    "        self.frame = frame\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.query(f\"Step % {frame} != 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_attribs = FEATURES\n",
    "cat_attribs = [LABEL]\n",
    "frame = 201\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=PolynomialDegree, include_bias=False))\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs))\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "my_full_pipeline = Pipeline([\n",
    "#         ('removeFirstFrame', RemoveFirstFrame(frame)),\n",
    "        ('featureSelection', full_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(raw_data, raw_data[\"isGood\"]):\n",
    "    strat_train_set = raw_data.iloc[train_index]\n",
    "    strat_test_set = raw_data.iloc[test_index]\n",
    "# strat_test_set[LABEL].value_counts() / len(strat_test_set)\n",
    "X_train = my_full_pipeline.fit_transform(strat_train_set)\n",
    "X_test = my_full_pipeline.fit_transform(strat_test_set)\n",
    "train_y = X_train[:,-1]\n",
    "train_set = X_train[:,:-1]\n",
    "test_y = X_test[:,-1]\n",
    "test_set = X_test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={0: 0.1, 1: 0.9}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=142,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('r...f',\n",
       "  max_iter=-1, probability=True, random_state=412, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# log_clf = LogisticRegression(random_state=142)\n",
    "# rnd_clf = RandomForestClassifier(random_state=432)\n",
    "# svm_clf = SVC(probability=True, random_state=412)\n",
    "log_clf = LogisticRegression(random_state=142, class_weight={0:p, 1:(1-p)})\n",
    "rnd_clf = RandomForestClassifier(random_state=432, class_weight={0:p, 1:(1-p)})\n",
    "svm_clf = SVC(probability=True, random_state=412, class_weight={0:p, 1:(1-p)})\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "log_clf.fit(train_set, train_y)\n",
    "rnd_clf.fit(train_set, train_y)\n",
    "svm_clf.fit(train_set, train_y)\n",
    "voting_clf.fit(train_set, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      " [[1558    4]\n",
      " [  32    6]]\n",
      "RandomForestClassifier \n",
      " [[1562    0]\n",
      " [  28   10]]\n",
      "SVC \n",
      " [[1559    3]\n",
      " [  31    7]]\n",
      "VotingClassifier \n",
      " [[1561    1]\n",
      " [  29    9]]\n"
     ]
    }
   ],
   "source": [
    "# check on training set\n",
    "n = 10\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "#     y_pred = clf.predict(train_set)\n",
    "    prob= clf.predict_proba(train_set)[:,1]\n",
    "    position_of_top_n = prob.argsort()[-n:][::-1]\n",
    "    threshold = prob[position_of_top_n][-1]\n",
    "    predict_y = np.zeros(len(train_y),)\n",
    "    predict_y[position_of_top_n] = 1\n",
    "#     predict_y = (test > threshold)\n",
    "#     print(threshold)\n",
    "    cm = confusion_matrix(train_y, predict_y)\n",
    "#     print(clf.__class__.__name__, \"\\n\", accuracy_score(train_y, predict_y))\n",
    "    print(clf.__class__.__name__, \"\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1MBA\n",
      "[[1942    9]\n",
      " [  49    1]]\n",
      "T0766\n",
      "[[1943    9]\n",
      " [  48    1]]\n",
      "T0784\n",
      "[[1939   10]\n",
      " [  52    0]]\n",
      "T0792\n",
      "[[1950    4]\n",
      " [  41    6]]\n",
      "T0803\n",
      "[[1943    9]\n",
      " [  48    1]]\n",
      "T0815\n",
      "[[1945    9]\n",
      " [  46    1]]\n",
      "T0833\n",
      "[[1914   10]\n",
      " [  49    0]]\n",
      "T251\n",
      "[[1940   10]\n",
      " [  51    0]]\n"
     ]
    }
   ],
   "source": [
    "time_stamp = f\"{datetime.today().strftime('%d_%h_%H%M%S')}\"\n",
    "for name, data in raw_test_data.groupby(\"Name\"):\n",
    "    print(name)\n",
    "    X = full_pipeline.fit_transform(data)\n",
    "    eval_y = X[:,-1]\n",
    "    eval_set = X[:,:-1]\n",
    "    test= log_clf.predict_proba(eval_set)[:,1]\n",
    "    position_of_top_n = test.argsort()[-n:][::-1]\n",
    "    threshold = test[position_of_top_n][-1]\n",
    "    predict_y = np.zeros(len(eval_y),)\n",
    "    predict_y[position_of_top_n] = 1\n",
    "\n",
    "    with open(f\"/Users/weilu/Research/data/structure_selector/p{p}_poly{PolynomialDegree}_{name}.csv\", \"w\") as f:\n",
    "        f.write(\"Result\\n\")\n",
    "        for i in test:\n",
    "            f.write(str(i) + \"\\n\")\n",
    "#     with open(f\"/Users/weilu/Research/data/structure_selector/{name}_results_{time_stamp}.csv\", \"w\") as f:\n",
    "#         f.write(\"Result\\n\")\n",
    "#         for i in test:\n",
    "#             f.write(str(i) + \"\\n\")\n",
    "\n",
    "#     predict_y = (test > threshold)\n",
    "#     print(threshold)\n",
    "    print(confusion_matrix(eval_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1MBA\n",
      "[[1943    8]\n",
      " [  48    2]]\n",
      "T0766\n",
      "[[1946    6]\n",
      " [  45    4]]\n",
      "T0784\n",
      "[[1939   10]\n",
      " [  52    0]]\n",
      "T0792\n",
      "[[1949    5]\n",
      " [  42    5]]\n",
      "T0803\n",
      "[[1944    8]\n",
      " [  47    2]]\n",
      "T0815\n",
      "[[1946    8]\n",
      " [  45    2]]\n",
      "T0833\n",
      "[[1915    9]\n",
      " [  48    1]]\n",
      "T251\n",
      "[[1941    9]\n",
      " [  50    1]]\n"
     ]
    }
   ],
   "source": [
    "time_stamp = f\"{datetime.today().strftime('%d_%h_%H%M%S')}\"\n",
    "for name, data in raw_test_data.groupby(\"Name\"):\n",
    "    print(name)\n",
    "    X = my_full_pipeline.fit_transform(data)\n",
    "    eval_y = X[:,-1]\n",
    "    eval_set = X[:,:-1]\n",
    "    test= log_clf.predict_proba(eval_set)[:,1]\n",
    "    position_of_top_n = test.argsort()[-n:][::-1]\n",
    "    threshold = test[position_of_top_n][-1]\n",
    "    predict_y = np.zeros(len(eval_y),)\n",
    "    predict_y[position_of_top_n] = 1\n",
    "\n",
    "\n",
    "#     predict_y = (test > threshold)\n",
    "#     print(threshold)\n",
    "    print(confusion_matrix(eval_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
