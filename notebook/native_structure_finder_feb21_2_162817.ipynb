{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_data = pd.read_csv(\"/Users/weilu/Research/data/test_data/test_data_4.csv\")\n",
    "raw_data_T0784 = raw_test_data.groupby(\"Name\").get_group(\"T0784\")\n",
    "raw_data_T0792 = raw_test_data.groupby(\"Name\").get_group(\"T0792\")\n",
    "# raw_data = pd.concat([raw_data_T0784, raw_data_T0792])\n",
    "raw_data = raw_data_T0792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Step', 'Qw', 'Rw', 'VTotal', 'QGO', 'Burial', 'Water', 'Rama', 'Chain',\n",
       "       'Chi', 'DSSP', 'P_AP', 'Helix', 'Frag_Mem', 'GDT', 'Name', 'Good'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1961\n",
       "1      49\n",
       "Name: Good, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[\"Good\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FEATURES = [\"Rw\", \"VTotal\", \"QGO\"]\n",
    "# FEATURES = [\"Rw\", \"VTotal\", \"QGO\", \"Burial\", \"Frag_Mem\", \"Water\"]\n",
    "# FEATURES = list(raw_test_data.columns[2:-3])\n",
    "FEATURES = ['Rw',\n",
    " 'VTotal',\n",
    " 'QGO',\n",
    " 'Burial',\n",
    " 'Water',\n",
    " 'Rama',\n",
    " 'DSSP',\n",
    " 'P_AP',\n",
    " 'Helix',\n",
    " 'Frag_Mem']\n",
    "# LABEL = \"Qw\"\n",
    "LABEL = \"Good\"\n",
    "PolynomialDegree = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "class RemoveFirstFrame(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, frame):\n",
    "        self.frame = frame\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.query(f\"Step % {frame} != 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I want to start with the simplest linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_attribs = FEATURES\n",
    "cat_attribs = [LABEL]\n",
    "frame = 201\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=PolynomialDegree, include_bias=False))\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs))\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "my_full_pipeline = Pipeline([\n",
    "        ('removeFirstFrame', RemoveFirstFrame(frame)),\n",
    "        ('featureSelection', full_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(raw_data, raw_data[\"Good\"]):\n",
    "    strat_train_set = raw_data.iloc[train_index]\n",
    "    strat_test_set = raw_data.iloc[test_index]\n",
    "# strat_test_set[LABEL].value_counts() / len(strat_test_set)\n",
    "X_train = my_full_pipeline.fit_transform(strat_train_set)\n",
    "X_test = my_full_pipeline.fit_transform(strat_test_set)\n",
    "train_y = X_train[:,-1]\n",
    "train_set = X_train[:,:-1]\n",
    "test_y = X_test[:,-1]\n",
    "test_set = X_test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={0: 0.1, 1: 0.9}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1421,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('...f',\n",
       "  max_iter=-1, probability=True, random_state=412, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "p = 0.1\n",
    "# log_clf = LogisticRegression(random_state=142)\n",
    "# rnd_clf = RandomForestClassifier(random_state=432)\n",
    "# svm_clf = SVC(probability=True, random_state=412)\n",
    "log_clf = LogisticRegression(random_state=142, class_weight={0:p, 1:(1-p)})\n",
    "rnd_clf = RandomForestClassifier(random_state=432, class_weight={0:p, 1:(1-p)})\n",
    "svm_clf = SVC(probability=True, random_state=412, class_weight={0:p, 1:(1-p)})\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "log_clf.fit(train_set, train_y)\n",
    "rnd_clf.fit(train_set, train_y)\n",
    "svm_clf.fit(train_set, train_y)\n",
    "voting_clf.fit(train_set, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-c0e21da45c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoting_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     y_pred = clf.predict(train_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mposition_of_top_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition_of_top_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_set' is not defined"
     ]
    }
   ],
   "source": [
    "# check on validation set\n",
    "n = 10\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "#     y_pred = clf.predict(train_set)\n",
    "    prob= clf.predict_proba(validation_set)[:,1]\n",
    "    position_of_top_n = prob.argsort()[-n:][::-1]\n",
    "    threshold = prob[position_of_top_n][-1]\n",
    "    predict_y = np.zeros(len(validation_y),)\n",
    "    predict_y[position_of_top_n] = 1\n",
    "#     predict_y = (test > threshold)\n",
    "#     print(threshold)\n",
    "    cm = confusion_matrix(validation_y, predict_y)\n",
    "#     print(clf.__class__.__name__, \"\\n\", accuracy_score(train_y, predict_y))\n",
    "    print(clf.__class__.__name__, \"\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      " [[1559    2]\n",
      " [  31    8]]\n",
      "RandomForestClassifier \n",
      " [[1561    0]\n",
      " [  29   10]]\n",
      "SVC \n",
      " [[1557    4]\n",
      " [  33    6]]\n",
      "VotingClassifier \n",
      " [[1561    0]\n",
      " [  29   10]]\n"
     ]
    }
   ],
   "source": [
    "# check on training set\n",
    "n = 10\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "#     y_pred = clf.predict(train_set)\n",
    "    prob= clf.predict_proba(train_set)[:,1]\n",
    "    position_of_top_n = prob.argsort()[-n:][::-1]\n",
    "    threshold = prob[position_of_top_n][-1]\n",
    "    predict_y = np.zeros(len(train_y),)\n",
    "    predict_y[position_of_top_n] = 1\n",
    "#     predict_y = (test > threshold)\n",
    "#     print(threshold)\n",
    "    cm = confusion_matrix(train_y, predict_y)\n",
    "#     print(clf.__class__.__name__, \"\\n\", accuracy_score(train_y, predict_y))\n",
    "    print(clf.__class__.__name__, \"\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.31462774, -0.15527758, -0.98023703,  0.20763854,  0.34406072,\n",
       "         0.35582871, -0.25780547,  0.61148341, -0.3305981 , -0.18003642]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rw',\n",
       " 'VTotal',\n",
       " 'QGO',\n",
       " 'Burial',\n",
       " 'Water',\n",
       " 'Rama',\n",
       " 'DSSP',\n",
       " 'P_AP',\n",
       " 'Helix',\n",
       " 'Frag_Mem']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1MBA\n",
      "[[1951   10]\n",
      " [  49    0]]\n",
      "T0766\n",
      "[[1961    0]\n",
      " [  39   10]]\n",
      "T0784\n",
      "[[1953    8]\n",
      " [  47    2]]\n",
      "T0792\n",
      "[[1958    3]\n",
      " [  42    7]]\n",
      "T0803\n",
      "[[1952    9]\n",
      " [  48    1]]\n",
      "T0815\n",
      "[[1949    8]\n",
      " [  51    2]]\n",
      "T0833\n",
      "[[1924    9]\n",
      " [  48    1]]\n",
      "T251\n",
      "[[1954    7]\n",
      " [  46    3]]\n"
     ]
    }
   ],
   "source": [
    "time_stamp = f\"{datetime.today().strftime('%d_%h_%H%M%S')}\"\n",
    "for name, data in raw_test_data.groupby(\"Name\"):\n",
    "    print(name)\n",
    "    X = full_pipeline.fit_transform(data)\n",
    "    eval_y = X[:,-1]\n",
    "    eval_set = X[:,:-1]\n",
    "    test= log_clf.predict_proba(eval_set)[:,1]\n",
    "    position_of_top_n = test.argsort()[-n:][::-1]\n",
    "    threshold = test[position_of_top_n][-1]\n",
    "    predict_y = np.zeros(len(eval_y),)\n",
    "    predict_y[position_of_top_n] = 1\n",
    "\n",
    "    with open(f\"/Users/weilu/Research/data/structure_selector/{name}_results_{time_stamp}.csv\", \"w\") as f:\n",
    "        f.write(\"Result\\n\")\n",
    "        for i in test:\n",
    "            f.write(str(i) + \"\\n\")\n",
    "\n",
    "#     predict_y = (test > threshold)\n",
    "#     print(threshold)\n",
    "    print(confusion_matrix(eval_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
